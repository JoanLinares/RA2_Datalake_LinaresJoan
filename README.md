# Data Lake & Warehouse - Polymarket Data Pipeline

Pipeline completo de ETL para extracci√≥n, transformaci√≥n y carga de datos de Polymarket a NeonDB (PostgreSQL Cloud). Implementa Arquitectura Medallion (Bronze ‚Üí Silver ‚Üí Gold).

## üèóÔ∏è Arquitectura del Proyecto

```
Fase 1: BRONZE (Extracci√≥n)          Fase 2: SILVER ‚Üí GOLD (Warehouse)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Polymarket API         ‚îÇ          ‚îÇ  Delta Lake (Raw Data)       ‚îÇ
‚îÇ                         ‚îÇ          ‚îÇ  ‚îú‚îÄ‚îÄ events/                 ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Events             ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ  ‚îú‚îÄ‚îÄ markets/               ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Markets            ‚îÇ          ‚îÇ  ‚îú‚îÄ‚îÄ series/                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Series             ‚îÇ          ‚îÇ  ‚îî‚îÄ‚îÄ tags/                   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Tags               ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
                                                  ‚îÇ Transformaci√≥n
                                                  ‚îú‚îÄ Normalizaci√≥n
                                                  ‚îú‚îÄ Limpieza
                                                  ‚îú‚îÄ Deduplicaci√≥n
                                                  ‚îÇ
                                          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                          ‚îÇ                ‚îÇ
                                          ‚ñº                ‚ñº
                                   Validaci√≥n      Carga en NeonDB
                                   üìä Integridad   üóÑÔ∏è Schema Dimensional
```

## üìä Fases del Pipeline

### Fase 1: BRONZE - Extracci√≥n (extractor_polymarket.py)
Extrae datos de la API p√∫blica de Polymarket con paralelizaci√≥n:
- **Endpoints**: `/events`, `/markets`, `/series`, `/tags`
- **Concurrencia**: 10 hilos por endpoint
- **Paginaci√≥n**: Page size 300-500 registros
- **Almacenamiento**: Delta Lake (datalake/raw/)
- **Reporte**: Volumetr√≠a y estad√≠sticas en JSON

**Datos extra√≠dos**:
- ~200K eventos
- ~450K mercados
- ~1.1K series
- ~5K tags

### Fase 2A: SILVER - Transformaci√≥n (DataTransformer)
Normalizaci√≥n y limpieza de datos en memoria antes de carga:

**Transformaciones**:
- ‚úì Normalizaci√≥n booleanos (True/'True'/1 ‚Üí boolean)
- ‚úì Normalizaci√≥n n√∫meros (US/EU/Mixed formats ‚Üí float)
- ‚úì Limpieza strings (trim, normalizar espacios, control)
- ‚úì Deserializaci√≥n JSON (precios, outcomes, tags)
- ‚úì Conversi√≥n fechas (ISO 8601 ‚Üí datetime)
- ‚úì Deduplicaci√≥n por ID
- ‚úì Validaci√≥n de tipos de datos

**M√©todos principales**:
```python
DataTransformer.normalize_boolean(value)      # True/False
DataTransformer.normalize_numeric(value)      # float
DataTransformer.clean_string(value)           # string normalizado
DataTransformer.normalize_prices(prices_str)  # ['0.45', '0.55'] ‚Üí [0.45, 0.55]
DataTransformer.normalize_outcomes(outcomes)  # "[' YES', ' NO']" ‚Üí ['YES', 'NO']
DataTransformer.parse_tags(tags_str)         # "['tag1', 'tag2']" ‚Üí ['tag1', 'tag2']
DataTransformer.validate_and_clean_events(df) # Pipeline completo eventos
DataTransformer.validate_and_clean_markets(df) # Pipeline completo mercados
```

### Fase 2B: Validaci√≥n Pre-Carga (WarehouseValidator)
Verifica integridad de datos antes de la carga:
- Existencia de archivos Delta Lake
- Estructura de datos esperada
- Campos requeridos vs opcionales

**M√©todos**:
```python
validator.validate_schema()        # Verifica tablas existen
validator.validate_data_integrity() # Integridad referencial
validator.generate_statistics()    # Estad√≠sticas
```

### Fase 2C: GOLD - Carga en NeonDB (WarehouseLoader)
Carga datos a PostgreSQL con modelo dimensional:

**Tablas creadas** (9 total):

**Dimensiones (5)**:
- `dim_date` - Calendario (date_id PK, year, month, day, quarter, day_of_week, is_weekend)
- `dim_event` - Eventos (event_id PK, title, category, ticker, dates, status flags)
- `dim_market` - Mercados (market_id PK, question, type, category, outcomes)
- `dim_series` - Series (series_id PK, slug, title)
- `dim_tag` - Tags √∫nicos (tag_id PK, tag_name UQ)

**Hechos (4)**:
- `fact_market_metrics` - (market_id FK, date_id FK, volume, liquidity, price, spread, etc.)
- `fact_event_metrics` - (event_id FK, date_id FK, active_markets, volume, liquidity)
- `fact_event_tag` - (event_id FK, tag_id FK) - Relaci√≥n N:N
- `fact_market_event` - (market_id FK, event_id FK) - Relaci√≥n N:N

**√çndices**:
- Categor√≠as (query performance)
- Tickers (b√∫squedas)
- Tipos de mercado (an√°lisis por tipo)

## üöÄ Ejecuci√≥n R√°pida

### Requisitos Previos
```bash
# 1. Python 3.9+
python --version

# 2. Variables de entorno (.env)
DATABASE_URL=postgresql://user:password@host/database

# 3. Dependencias
uv sync  # o: pip install -r requirements.txt
```

### Ejecuci√≥n Principal
```bash
# Ejecuta el pipeline completo (Extracci√≥n ‚Üí Transformaci√≥n ‚Üí Carga ‚Üí Validaci√≥n)
python main.py
```

**Flujo autom√°tico**:
1. ‚úÖ Verifica si `datalake/raw` existe
2. ‚úÖ Si NO existe ‚Üí ejecuta **extractor_polymarket.py**
3. ‚úÖ Ejecuta **DataTransformer** (normalizaci√≥n)
4. ‚úÖ Ejecuta **WarehouseValidator** (validaci√≥n)
5. ‚úÖ Ejecuta **WarehouseLoader** (carga NeonDB)

### Ejecuci√≥n Individual

#### Phase 1: Extracci√≥n
```bash
python extractor_polymarket.py
# Output: datalake/raw/{events,markets,series,tags}/
#         datalake/volumetry_report.json
```

#### Phase 2A: Transformaci√≥n (standalone)
```bash
python -c "
from src.utils.transformer_data import DataTransformer
from deltalake import DeltaTable
import pandas as pd

df = DeltaTable('datalake/raw/events').to_pandas()
df_clean = DataTransformer.validate_and_clean_events(df)
print(f'Eventos limpiados: {len(df_clean)} registros')
"
```

#### Phase 2C: Carga (sin validaci√≥n previa)
```bash
python -c "
from src.warehouse.loader_NeonDB import WarehouseLoader
import os

loader = WarehouseLoader(os.getenv('DATABASE_URL'))
loader.connect()
loader.load_all()
"
```

#### Verificar Conexi√≥n NeonDB
```bash
python test_connection.py
```

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ main.py                          # üéØ PUNTO DE ENTRADA (ejecuta todo)
‚îú‚îÄ‚îÄ extractor_polymarket.py          # Fase 1: Extracci√≥n de API
‚îú‚îÄ‚îÄ test_connection.py               # Verificaci√≥n de conexi√≥n NeonDB
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ warehouse/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader_NeonDB.py        # WarehouseLoader - Carga a PostgreSQL
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer_data.py      # DataTransformer - Normalizaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validator_warehouse.py   # WarehouseValidator - Validaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extractor/                   # (Reservado para fase 1 futura)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ datalake/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # Bronze - Datos crudos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events/                 (Delta Lake)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ markets/                (Delta Lake)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ series/                 (Delta Lake)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tags/                   (Delta Lake)
‚îÇ   ‚îî‚îÄ‚îÄ volumetry_report.json        # Estad√≠sticas de extracci√≥n
‚îÇ
‚îú‚îÄ‚îÄ .env                             # Variables de entorno
‚îú‚îÄ‚îÄ pyproject.toml                   # Dependencias (Python)
‚îú‚îÄ‚îÄ README.md                        # Este archivo
‚îî‚îÄ‚îÄ WAREHOUSE_README.md              # Documentaci√≥n detallada warehouse
```

## üîß Configuraci√≥n

### 1. Variables de Entorno (.env)

```bash
# Conexi√≥n a NeonDB (PostgreSQL en la nube)
DATABASE_URL=postgresql://user:password@host:port/database?sslmode=require

# Ejemplo NeonDB real:
DATABASE_URL=postgresql://neondb_owner:npg_abc123@ep-xxx.c-3.region.aws.neon.tech/neondb?sslmode=require&channel_binding=require
```

### 2. Dependencias (pyproject.toml)

```toml
[project]
dependencies = [
    "requests>=2.31.0",           # API HTTP
    "pandas>=2.0.0",              # Datos tabular
    "pyarrow>=14.0.0",            # Columnar
    "deltalake>=0.15.0",          # Delta Lake
    "python-dotenv>=1.0.0",       # .env
    "psycopg2-binary>=2.9.0",     # PostgreSQL
    "sqlalchemy>=2.0.0"           # ORM/queries
]
```

### 3. Instalaci√≥n

```bash
# Opci√≥n 1: Con uv (recomendado)
uv sync

# Opci√≥n 2: Con pip
pip install -r requirements.txt

# Opci√≥n 3: Manual
pip install requests pandas pyarrow deltalake python-dotenv psycopg2-binary sqlalchemy
```

## üìä Estad√≠sticas & Monitoreo

### Volumetr√≠a
Se genera autom√°ticamente en `datalake/volumetry_report.json`:
```json
{
  "fecha_extraccion": "2024-01-15T10:30:00",
  "resumen": {
    "registros_por_entidad": {
      "events": 200000,
      "markets": 450000,
      "series": 1100,
      "tags": 5000
    },
    "distribucion_markets": {
      "total": 450000,
      "activos": 380000,
      "cerrados": 70000,
      "porcentaje_activos": 84.44
    }
  }
}
```

### Logs del Pipeline
```
2024-01-15 10:30:45 - INFO - FASE 1: EXTRACCI√ìN DE DATOS DE POLYMARKET
2024-01-15 10:30:45 - INFO - Iniciando extracci√≥n de events con 10 hilos...
2024-01-15 10:31:25 - INFO - events: Extracci√≥n completada. Total: 200000 registros
2024-01-15 10:32:15 - INFO - ‚úì FASE 1 COMPLETADA
2024-01-15 10:32:16 - INFO - FASE 2A: TRANSFORMACI√ìN DE DATOS
2024-01-15 10:32:20 - INFO - Limpiando eventos... Removidos 100 duplicados
2024-01-15 10:32:22 - INFO - Eventos limpiados: 199900 registros v√°lidos
2024-01-15 10:32:45 - INFO - ‚úì FASE 2A COMPLETADA
2024-01-15 10:32:46 - INFO - FASE 2C: CARGA EN NEONDB
2024-01-15 10:33:05 - INFO - Conectado a NeonDB exitosamente
2024-01-15 10:33:06 - INFO - Tabla dim_event creada
2024-01-15 10:34:30 - INFO - Cargados 200000 eventos
2024-01-15 10:35:45 - INFO - ‚úì VALIDACI√ìN COMPLETADA EXITOSAMENTE
2024-01-15 10:36:00 - INFO - PIPELINE COMPLETADO EXITOSAMENTE
```

### Validaci√≥n Post-Carga
```
=== VALIDACI√ìN DE ESQUEMA ===
‚úì Dimensi√≥n Temporal         (dim_date):               365 registros
‚úì Dimensi√≥n Eventos          (dim_event):          200000 registros
‚úì Dimensi√≥n Mercados         (dim_market):         450000 registros
‚úì Dimensi√≥n Series           (dim_series):            1100 registros
‚úì Dimensi√≥n Tags             (dim_tag):               5000 registros
‚úì Relaciones Event-Tag       (fact_event_tag):    1200000 registros
‚úì Relaciones Market-Event    (fact_market_event):  500000 registros
‚úì M√©tricas de Mercados       (fact_market_metrics):450000 registros
‚úì M√©tricas de Eventos        (fact_event_metrics):  200000 registros

=== VALIDACI√ìN DE INTEGRIDAD ===
‚úì dim_event: 200000 IDs √∫nicos (v√°lido)
‚úì dim_market: 450000 IDs √∫nicos (v√°lido)
‚úì fact_event_tag: Sin relaciones hu√©rfanas (v√°lido)
‚úì fact_market_event: Sin relaciones hu√©rfanas (v√°lido)

=== ESTAD√çSTICAS DEL WAREHOUSE ===
Eventos:
  Total: 200,000 registros
  Activos: 150,000
  Cerrados: 50,000
  Categor√≠as √∫nicas: 45
```

## üéØ Casos de Uso

### Caso 1: Pipeline Completo (Recomendado)
```bash
python main.py
# Ejecuta: Extracci√≥n ‚Üí Transformaci√≥n ‚Üí Carga ‚Üí Validaci√≥n
# Tiempo estimado: 3-5 minutos
```

### Caso 2: Solo Actualizar Datos del Warehouse
```bash
# Si ya tienes datalake/raw poblado:
python main.py  # Saltar√° extracci√≥n autom√°ticamente
```

### Caso 3: Extracci√≥n Incremental
```bash
# Ejecuta solo extractor (mantiene datos previos)
python extractor_polymarket.py
```

### Caso 4: Testing/Debugging
```bash
# Verificar conexi√≥n
python test_connection.py

# Verificaci√≥n manual de transformaci√≥n
python -c "from src.utils.transformer_data import DataTransformer; ..."

# Verificar NeonDB tiene datos
psql "postgresql://..." -c "SELECT COUNT(*) FROM dim_market;"
```

## ‚ö†Ô∏è Troubleshooting

### Error: DATABASE_URL not found
```
‚ùå DATABASE_URL no encontrada en .env
```
**Soluci√≥n**:
```bash
# Crear/verificar .env
echo "DATABASE_URL=postgresql://..." > .env
```

### Error: Connection refused (Polymarket API)
```
Error al obtener events offset 0: Connection refused
```
**Soluci√≥n**:
```bash
# Verificar conectividad
python -c "import requests; print(requests.get('https://gamma-api.polymarket.com/events').status_code)"
```

### Error: Delta Lake not found
```
FileNotFoundError: datalake/raw/events
```
**Soluci√≥n**:
```bash
# Ejecutar extracci√≥n
python extractor_polymarket.py

# O ejecutar main.py (detecta autom√°ticamente)
python main.py
```

### Error: Connection timeout (NeonDB)
```
psycopg2.OperationalError: timeout expired
```
**Soluci√≥n**:
```bash
# Verificar acceso a NeonDB
python test_connection.py

# Verificar credentials en .env
# Verificar firewall/IP whitelist en NeonDB console
```

### Error: Schema already exists
```
psycopg2.errors.DuplicateTable: relation "dim_event" already exists
```
**Soluci√≥n**:
El script `loader_NeonDB.py` elimina autom√°ticamente tablas previas. Si hay conflicto:
```bash
# Conectar a NeonDB y limpiar manualmente
psql "postgresql://..." -c "DROP TABLE IF EXISTS dim_event CASCADE;"
```

## üìà Performance Tuning

| Fase | M√©trica | Valor | Optimizaci√≥n |
|------|---------|-------|--------------|
| Extracci√≥n | Tiempo | 2 min | ‚Üë `threads` en CONFIG |
| Transformaci√≥n | Memoria | 2GB | ‚Üì `batch_size` |
| Carga | I/O | 50K/s | ‚Üë `page_size` en execute_values |
| Validaci√≥n | Queries | <1s | ‚úì Usa √≠ndices |

## üîê Seguridad

- ‚úì DATABASE_URL en .env (git-ignored)
- ‚úì SSL mode en NeonDB (sslmode=require)
- ‚úì Channel binding (protecci√≥n MITM)
- ‚úì Credenciales no loguean
- ‚úì Data sanitization en inputs

## üìö Recursos

- [Polymarket API Docs](https://docs.polymarket.com/)
- [Delta Lake Format](https://delta.io/)
- [NeonDB Docs](https://neon.tech/docs/)
- [PostgreSQL Docs](https://www.postgresql.org/docs/)
- [PyArrow Documentation](https://arrow.apache.org/docs/python/)

## üë®‚Äçüíª Desarrollo y Contribuciones

### Agregar nueva transformaci√≥n
```python
# En src/utils/transformer_data.py
class DataTransformer:
    @staticmethod
    def normalize_custom(value):
        """Tu transformaci√≥n"""
        # ...
        return transformed_value
```

### Agregar nueva validaci√≥n
```python
# En src/utils/validator_warehouse.py
class WarehouseValidator:
    def validate_custom_rule(self):
        """Tu validaci√≥n"""
        # ...
        return is_valid
```

### Agregar nueva tabla fact/dimension
```python
# En src/warehouse/loader_NeonDB.py
class WarehouseLoader:
    def load_dim_custom(self, data):
        """Tu carga"""
        insert_query = "INSERT INTO dim_custom ..."
        # ...
```

## üìÑ Licencia

Proyecto acad√©mico - RA2 S3 LinaresJoan

## üìû Contacto

Joan Linares - [GitHub](https://github.com/JoanLinares)

---

**√öltima actualizaci√≥n**: Febrero 2026  
**Estado**: Producci√≥n ‚úÖ  
**Versi√≥n**: 2.0 (Fase 1 + Fase 2 completa)

